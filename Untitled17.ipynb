{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbEMgMpKg5iLIUkPLRY7UT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deekshith-Proj/CVD/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "import zipfile\n",
        "zip_ref=zipfile.ZipFile('/content/dogs-vs-cats.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "zip_ref=zipfile.ZipFile('/content/train.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "zip_ref=zipfile.ZipFile('/content/test1.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4rTFbsoyJ_W",
        "outputId": "b31bb592-94d3-4096-bc97-238f8da44c26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 807M/812M [00:06<00:00, 183MB/s]\n",
            "100% 812M/812M [00:06<00:00, 128MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyKvwZ9Zx-XG",
        "outputId": "242bce61-1e99-4562-b400-af4b030180db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: /content/train (224, 224) batch: 16\n"
          ]
        }
      ],
      "source": [
        "# CELL A: config & helpers\n",
        "import os, gc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0, ResNet50, MobileNetV2\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_pre\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as res_pre\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mob_pre\n",
        "\n",
        "# Paths (match your Colab)\n",
        "DATA_DIR = \"/content/train\"\n",
        "IMG_SIZE = (224,224)   # if memory tight, try (160,160)\n",
        "BATCH_SIZE = 16        # reduce if still high memory\n",
        "SEED = 42\n",
        "\n",
        "print(\"Config:\", DATA_DIR, IMG_SIZE, \"batch:\", BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL B: count images and sanity-check folder layout\n",
        "cats_dir = os.path.join(DATA_DIR, \"cats\")\n",
        "dogs_dir = os.path.join(DATA_DIR, \"dogs\")\n",
        "\n",
        "n_cats = len([f for f in os.listdir(cats_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "n_dogs = len([f for f in os.listdir(dogs_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
        "n_samples = n_cats + n_dogs\n",
        "print(\"cats:\", n_cats, \"dogs:\", n_dogs, \"total:\", n_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYP4eHDnyv76",
        "outputId": "6a5e3c57-7df8-4c12-f975-cd9daae8f3fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats: 12500 dogs: 12500 total: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "print(\"Number of batches:\", tf.data.experimental.cardinality(train_ds).numpy())\n",
        "for imgs, labels in train_ds.take(1):\n",
        "    print(\"Batch images shape:\", imgs.shape, \"Batch labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecPNghiOzSHX",
        "outputId": "11c3e9c6-34a5-4559-fa1f-87c753f139e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches: 1563\n",
            "Batch images shape: (16, 224, 224, 3) Batch labels shape: (16,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL C: streaming tf.data for inference (no caching)\n",
        "def make_dataset_for_predict(data_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False):\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        labels='inferred',\n",
        "        label_mode='int',\n",
        "        image_size=image_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle\n",
        "    )\n",
        "    # convert to float32 (not dividing by 255 here ‚Äî preprocessors handle that)\n",
        "    ds = ds.map(lambda x,y: (tf.cast(x, tf.float32), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "predict_ds = make_dataset_for_predict(DATA_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwJLvpaWzeoc",
        "outputId": "8b03091b-1f91-4f15-b3dc-98fe95e2dd92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL D: build feature extractors (global avg pooled)\n",
        "def build_extractor(model_cls):\n",
        "    base = model_cls(weights=\"imagenet\", include_top=False,\n",
        "                     input_shape=(*IMG_SIZE,3), pooling=\"avg\")\n",
        "    return base\n",
        "\n",
        "# instantiate\n",
        "efficientnet = build_extractor(EfficientNetB0)\n",
        "resnet = build_extractor(ResNet50)\n",
        "mobilenet = build_extractor(MobileNetV2)\n",
        "print(\"Built extractors.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJF8ecBJzk9p",
        "outputId": "73e3b7e8-1ec6-4e3d-ddca-82998c85e8e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built extractors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL E: extract features to a memmap file (streaming)\n",
        "def extract_to_memmap(model, preprocess_fn, ds, out_path, n_samples, batch_size=BATCH_SIZE, dtype=np.float32):\n",
        "    # first pass: get feature vector length by predicting on single batch\n",
        "    for batch_imgs, _ in ds.take(1):\n",
        "        imgs_np = batch_imgs.numpy().astype(np.float32)\n",
        "        imgs_pre = preprocess_fn(imgs_np.copy())\n",
        "        feat_sample = model.predict(imgs_pre, batch_size=imgs_pre.shape[0])\n",
        "        feat_dim = feat_sample.shape[1]\n",
        "        break\n",
        "\n",
        "    # create memmap file\n",
        "    mm = np.memmap(out_path, dtype=dtype, mode='w+', shape=(n_samples, feat_dim))\n",
        "    print(f\"Created memmap {out_path} shape {(n_samples, feat_dim)}\")\n",
        "\n",
        "    # write features batchwise\n",
        "    idx = 0\n",
        "    for batch_imgs, _ in ds:\n",
        "        imgs_np = batch_imgs.numpy().astype(np.float32)\n",
        "        imgs_pre = preprocess_fn(imgs_np.copy())\n",
        "        feats = model.predict(imgs_pre, batch_size=imgs_pre.shape[0], verbose=0)\n",
        "        b = feats.shape[0]\n",
        "        mm[idx:idx+b] = feats\n",
        "        idx += b\n",
        "        # flush to disk and free mem\n",
        "        mm.flush()\n",
        "        del feats, imgs_np, imgs_pre\n",
        "        gc.collect()\n",
        "    print(\"Done writing to\", out_path)\n",
        "    return out_path\n",
        "\n",
        "# Example usage will be in next cell\n"
      ],
      "metadata": {
        "id": "tmopOYI5zr8f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL F: run extraction sequentially to avoid memory spikes\n",
        "n = n_samples\n",
        "out_dir = \"/content/features\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# IMPORTANT: use predict_ds created earlier (same ordering)\n",
        "# EfficientNet\n",
        "eff_path = os.path.join(out_dir, \"feat_eff.dat\")\n",
        "extract_to_memmap(efficientnet, eff_pre, predict_ds, eff_path, n_samples)\n",
        "\n",
        "# clear session if memory still high\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "# ResNet\n",
        "res_path = os.path.join(out_dir, \"feat_res.dat\")\n",
        "extract_to_memmap(resnet, res_pre, predict_ds, res_path, n_samples)\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "# MobileNet\n",
        "mob_path = os.path.join(out_dir, \"feat_mob.dat\")\n",
        "extract_to_memmap(mobilenet, mob_pre, predict_ds, mob_path, n_samples)\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0qZJIIX0CmA",
        "outputId": "a076af0d-3547-478e-ef8a-f3f60f91a94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step\n",
            "Created memmap /content/features/feat_eff.dat shape (25000, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL G: combine feature memmaps into a single memmap by slicing (streaming)\n",
        "import numpy.lib.format as nplf\n",
        "\n",
        "def combine_to_memmap(paths, out_path, n_samples):\n",
        "    # open each memmap read-only\n",
        "    mms = [np.memmap(p, mode='r') for p in paths]\n",
        "    dims = []\n",
        "    for mm in mms:\n",
        "        feat_dim = mm.size // n_samples\n",
        "        dims.append(feat_dim)\n",
        "    total_dim = sum(dims)\n",
        "    out_mm = np.memmap(out_path, dtype=np.float32, mode='w+', shape=(n_samples, total_dim))\n",
        "    start = 0\n",
        "    for mm, d in zip(mms, dims):\n",
        "        mm_reshaped = mm.reshape(n_samples, d)\n",
        "        out_mm[:, start:start+d] = mm_reshaped\n",
        "        start += d\n",
        "        # free\n",
        "        del mm_reshaped\n",
        "    out_mm.flush()\n",
        "    return out_path\n",
        "\n",
        "combined_path = \"/content/features/feat_combined.dat\"\n",
        "combine_to_memmap([eff_path, res_path, mob_path], combined_path, n_samples)\n",
        "print(\"Combined memmap at\", combined_path)\n"
      ],
      "metadata": {
        "id": "7CJls4TF0EXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL H: use memmap for sklearn training ‚Äî load in chunks to train or use partial_fit\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "total_dim = np.memmap(combined_path, mode='r').shape[1] // 1\n",
        "combined_mm = np.memmap(combined_path, dtype=np.float32, mode='r', shape=(n_samples, -1))\n",
        "idxs = np.arange(n_samples)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_idxs, test_idxs = train_test_split(idxs, test_size=0.2, random_state=SEED, stratify=np.concatenate([np.zeros(n_cats), np.ones(n_dogs)]))\n",
        "\n",
        "# If RAM allows, load train features in chunks and fit scaler & classifiers.\n",
        "def load_rows(mm, indices):\n",
        "    # returns a numpy array for the given indices (this creates a copy)\n",
        "    return mm[indices]\n",
        "\n",
        "X_train = load_rows(combined_mm, train_idxs)\n",
        "X_test  = load_rows(combined_mm, test_idxs)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# train base classifiers (same as before)\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=SEED)\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=SEED)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "lr  = LogisticRegression(max_iter=2000, random_state=SEED)\n",
        "\n",
        "rf.fit(X_train, np.take(np.concatenate([np.zeros(n_cats), np.ones(n_dogs)]), train_idxs))\n",
        "svm.fit(X_train, np.take(np.concatenate([np.zeros(n_cats), np.ones(n_dogs)]), train_idxs))\n",
        "knn.fit(X_train, np.take(np.concatenate([np.zeros(n_cats), np.ones(n_dogs)]), train_idxs))\n",
        "lr.fit(X_train, np.take(np.concatenate([np.zeros(n_cats), np.ones(n_dogs)]), train_idxs))\n",
        "\n",
        "print(\"Trained base models on memmap-derived arrays.\")\n"
      ],
      "metadata": {
        "id": "0FEmhw9C0Iqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate ---\n",
        "y_pred = meta.predict(test_meta)\n",
        "y_prob = meta.predict_proba(test_meta)[:,1]\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "ayavnDgu0MG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict single image ---\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "def predict_image(path):\n",
        "    img = load_img(path, target_size=IMG_SIZE)\n",
        "    arr = img_to_array(img).astype(np.float32)\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "\n",
        "    f1 = extract_batch_features(efficientnet, eff_pre, arr)\n",
        "    f2 = extract_batch_features(resnet, res_pre, arr)\n",
        "    f3 = extract_batch_features(mobilenet, mob_pre, arr)\n",
        "\n",
        "    feats = np.concatenate([f1, f2, f3], axis=1)\n",
        "    feats = scaler.transform(feats)\n",
        "\n",
        "    meta_feats = np.column_stack([\n",
        "        rf.predict_proba(feats)[:,1],\n",
        "        svm.predict_proba(feats)[:,1],\n",
        "        knn.predict_proba(feats)[:,1],\n",
        "        lr.predict_proba(feats)[:,1]\n",
        "    ])\n",
        "\n",
        "    prob = meta.predict_proba(meta_feats)[0,1]\n",
        "    print(f\"Dog probability: {prob:.3f}\")\n",
        "    print(\"Prediction:\", \"Dog üê∂\" if prob >= 0.5 else \"Cat üê±\")\n"
      ],
      "metadata": {
        "id": "5c4u8HBS0Pwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}